{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install natsort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort # 파일 숫자 정렬용 라이브러리\n",
    "import os\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. MFCC 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/\n",
    "#https://stackoverflow.com/questions/52841335/how-can-i-pad-wav-file-to-specific-length\n",
    "from librosa.util import fix_length\n",
    "from librosa import load\n",
    "from tqdm import tqdm\n",
    "\n",
    "def features_extractor(file):\n",
    "    #load the file (audio)\n",
    "    file_name = file\n",
    "    sf = 44100 # sampling frequency of wav file\n",
    "    \n",
    "    audio, sample_rate = librosa.load(file_name, sr=sf, mono=True) # mono=True converts stereo audio to mono\n",
    "        \n",
    "    #we extract mfcc'\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, n_mfcc=20, sr=sf) ## --> n_mfcc : 20 ~ 50\n",
    "    #print(\"mfccs_features\",mfccs_features.shape)\n",
    "\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0) ## 평균으로 출력\n",
    "    \n",
    "    #print(\"mfccs_scaled_features\", mfccs_scaled_features.shape)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. feature 데이터 가공하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = natsort.natsorted(os.listdir(\"music3_audio_wav\"))\n",
    "\n",
    "extracted_features=[]\n",
    "extracted_len_features=[]\n",
    "file_total_len = 1 # feature_input 길이 ex). 1초, 2초\n",
    "\n",
    "start_sec = 5 # 파일 갯수 정하기 ex 1 ~ 24\n",
    "end_sec = 472\n",
    "count = 0\n",
    "\n",
    "for filename in file_list[start_sec-1:end_sec]:\n",
    "    file_name = os.path.join(\"music3_audio_wav\", filename) ## 만약에 2초마다 붙이고 싶으면\n",
    "    # print(file_name)\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_len_features = np.concatenate((extracted_len_features, data))\n",
    "    count+=1\n",
    "    \n",
    "    if (count == file_total_len):\n",
    "        extracted_features.append(extracted_len_features)\n",
    "        \n",
    "        extracted_len_features=[]\n",
    "        count = 0\n",
    "\n",
    "    \n",
    "extracted_features_df=pd.DataFrame(extracted_features)\n",
    "\n",
    "for column_name in extracted_features_df:\n",
    "    extracted_features_df.rename(columns={column_name:\"f\"+str(column_name+1)},inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. skeleton 데이터 가공하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = pd.read_csv('music3_hand_result.csv')\n",
    "\n",
    "extracted_skeleton=[] ### 궁금한게 초 길이 ## 다음 순차적으로 데이터 이어 붙이기 해야할 것같음\n",
    "\n",
    "interval = 1\n",
    "start_frame = (start_sec+interval) * 30 # 실제 csv : ( row = 2부터 시작 ) // 한 칸씩 떼기\n",
    "end_frame = (end_sec+interval) * 30\n",
    "\n",
    "frame_count = 30 # 1초 = 30 frame\n",
    "\n",
    "skeleton_col = ['INDEX_FINGER_PIP_LX'] # 원하는 column 에 대해서만 ex. 6번 = INDEX_FINGER_PIP_LX\n",
    "\n",
    "for frame_num in range(start_frame, end_frame + 1, frame_count): # start_frame ~ end_frame\n",
    "    extracted_total_skeleton=[]\n",
    "    for col in skeleton_col:\n",
    "        extracted_skeleton_list = list(skeleton.loc[frame_num:(frame_num+frame_count)-1, col])\n",
    "        extracted_total_skeleton = np.concatenate((extracted_total_skeleton, extracted_skeleton_list))\n",
    "    extracted_skeleton.append(extracted_total_skeleton)\n",
    "\n",
    "extracted_skeleton_df = pd.DataFrame(extracted_skeleton)\n",
    "\n",
    "for column_name in extracted_skeleton_df:\n",
    "    extracted_skeleton_df.rename(columns={column_name:\"s\"+str(column_name+1)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>s21</th>\n",
       "      <th>s22</th>\n",
       "      <th>s23</th>\n",
       "      <th>s24</th>\n",
       "      <th>s25</th>\n",
       "      <th>s26</th>\n",
       "      <th>s27</th>\n",
       "      <th>s28</th>\n",
       "      <th>s29</th>\n",
       "      <th>s30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1131.370728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>624.980011</td>\n",
       "      <td>624.515686</td>\n",
       "      <td>625.626717</td>\n",
       "      <td>626.742325</td>\n",
       "      <td>627.196388</td>\n",
       "      <td>628.167343</td>\n",
       "      <td>629.288254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1131.370728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>741.540604</td>\n",
       "      <td>740.039139</td>\n",
       "      <td>738.791885</td>\n",
       "      <td>741.518402</td>\n",
       "      <td>965.318375</td>\n",
       "      <td>969.375534</td>\n",
       "      <td>968.527985</td>\n",
       "      <td>971.133652</td>\n",
       "      <td>974.208984</td>\n",
       "      <td>977.286148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-600.161072</td>\n",
       "      <td>83.292892</td>\n",
       "      <td>-0.855606</td>\n",
       "      <td>-6.247252</td>\n",
       "      <td>9.514754</td>\n",
       "      <td>1.260838</td>\n",
       "      <td>-3.974618</td>\n",
       "      <td>-1.122937</td>\n",
       "      <td>-2.315084</td>\n",
       "      <td>-0.782426</td>\n",
       "      <td>...</td>\n",
       "      <td>986.818085</td>\n",
       "      <td>990.895920</td>\n",
       "      <td>992.306366</td>\n",
       "      <td>992.766876</td>\n",
       "      <td>748.146439</td>\n",
       "      <td>751.155319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>747.904053</td>\n",
       "      <td>748.794479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-314.307526</td>\n",
       "      <td>294.265228</td>\n",
       "      <td>-18.235453</td>\n",
       "      <td>-43.241116</td>\n",
       "      <td>23.966576</td>\n",
       "      <td>1.268239</td>\n",
       "      <td>-17.122757</td>\n",
       "      <td>-0.672371</td>\n",
       "      <td>-0.464282</td>\n",
       "      <td>-2.445030</td>\n",
       "      <td>...</td>\n",
       "      <td>1016.501160</td>\n",
       "      <td>762.037048</td>\n",
       "      <td>757.047043</td>\n",
       "      <td>1000.429916</td>\n",
       "      <td>997.305298</td>\n",
       "      <td>747.657471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>991.153412</td>\n",
       "      <td>993.239441</td>\n",
       "      <td>1000.373993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-286.899841</td>\n",
       "      <td>295.656647</td>\n",
       "      <td>-25.355766</td>\n",
       "      <td>-38.542938</td>\n",
       "      <td>30.198391</td>\n",
       "      <td>-1.347459</td>\n",
       "      <td>-17.192017</td>\n",
       "      <td>3.857743</td>\n",
       "      <td>2.328808</td>\n",
       "      <td>1.493181</td>\n",
       "      <td>...</td>\n",
       "      <td>982.200012</td>\n",
       "      <td>978.328552</td>\n",
       "      <td>974.822617</td>\n",
       "      <td>968.667984</td>\n",
       "      <td>966.926193</td>\n",
       "      <td>941.512299</td>\n",
       "      <td>964.371872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>-499.660553</td>\n",
       "      <td>226.774216</td>\n",
       "      <td>24.239323</td>\n",
       "      <td>-34.519707</td>\n",
       "      <td>-4.645311</td>\n",
       "      <td>-6.661662</td>\n",
       "      <td>-24.467012</td>\n",
       "      <td>-17.183765</td>\n",
       "      <td>-8.609711</td>\n",
       "      <td>-11.367735</td>\n",
       "      <td>...</td>\n",
       "      <td>676.137314</td>\n",
       "      <td>553.682327</td>\n",
       "      <td>552.782555</td>\n",
       "      <td>552.999458</td>\n",
       "      <td>676.048203</td>\n",
       "      <td>675.833435</td>\n",
       "      <td>675.321121</td>\n",
       "      <td>675.325851</td>\n",
       "      <td>675.530701</td>\n",
       "      <td>675.846405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>-519.125061</td>\n",
       "      <td>196.360794</td>\n",
       "      <td>20.975153</td>\n",
       "      <td>-37.906445</td>\n",
       "      <td>-8.972572</td>\n",
       "      <td>-2.429075</td>\n",
       "      <td>-21.040472</td>\n",
       "      <td>-20.170307</td>\n",
       "      <td>-9.023230</td>\n",
       "      <td>-9.146351</td>\n",
       "      <td>...</td>\n",
       "      <td>688.920212</td>\n",
       "      <td>689.198761</td>\n",
       "      <td>690.185700</td>\n",
       "      <td>689.881744</td>\n",
       "      <td>688.283386</td>\n",
       "      <td>688.633118</td>\n",
       "      <td>689.013825</td>\n",
       "      <td>689.306183</td>\n",
       "      <td>689.485626</td>\n",
       "      <td>689.206009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>-664.719604</td>\n",
       "      <td>237.568832</td>\n",
       "      <td>34.023125</td>\n",
       "      <td>-27.980137</td>\n",
       "      <td>4.174069</td>\n",
       "      <td>5.959048</td>\n",
       "      <td>-15.679664</td>\n",
       "      <td>-12.246822</td>\n",
       "      <td>-1.270034</td>\n",
       "      <td>-7.274833</td>\n",
       "      <td>...</td>\n",
       "      <td>687.667694</td>\n",
       "      <td>687.689285</td>\n",
       "      <td>687.410126</td>\n",
       "      <td>688.717880</td>\n",
       "      <td>689.070664</td>\n",
       "      <td>689.700165</td>\n",
       "      <td>690.522080</td>\n",
       "      <td>690.021896</td>\n",
       "      <td>691.720810</td>\n",
       "      <td>691.699905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-642.387573</td>\n",
       "      <td>211.626724</td>\n",
       "      <td>58.024738</td>\n",
       "      <td>-17.231331</td>\n",
       "      <td>-9.627137</td>\n",
       "      <td>5.180705</td>\n",
       "      <td>-0.984878</td>\n",
       "      <td>-5.853268</td>\n",
       "      <td>-4.523614</td>\n",
       "      <td>-8.410495</td>\n",
       "      <td>...</td>\n",
       "      <td>689.105835</td>\n",
       "      <td>686.911392</td>\n",
       "      <td>686.934891</td>\n",
       "      <td>686.820145</td>\n",
       "      <td>686.609802</td>\n",
       "      <td>688.552475</td>\n",
       "      <td>689.970245</td>\n",
       "      <td>688.107758</td>\n",
       "      <td>687.123413</td>\n",
       "      <td>687.262878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>-739.442017</td>\n",
       "      <td>198.660782</td>\n",
       "      <td>43.886757</td>\n",
       "      <td>-12.170009</td>\n",
       "      <td>-4.475622</td>\n",
       "      <td>0.800751</td>\n",
       "      <td>-2.979800</td>\n",
       "      <td>-0.826931</td>\n",
       "      <td>-0.203965</td>\n",
       "      <td>-7.412817</td>\n",
       "      <td>...</td>\n",
       "      <td>682.296982</td>\n",
       "      <td>681.843262</td>\n",
       "      <td>682.140198</td>\n",
       "      <td>683.012314</td>\n",
       "      <td>683.336716</td>\n",
       "      <td>683.770065</td>\n",
       "      <td>683.572769</td>\n",
       "      <td>683.122482</td>\n",
       "      <td>683.573990</td>\n",
       "      <td>683.046722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1          f2         f3         f4         f5        f6  \\\n",
       "0   -1131.370728    0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       "1   -1131.370728    0.000000   0.000000   0.000000   0.000000  0.000000   \n",
       "2    -600.161072   83.292892  -0.855606  -6.247252   9.514754  1.260838   \n",
       "3    -314.307526  294.265228 -18.235453 -43.241116  23.966576  1.268239   \n",
       "4    -286.899841  295.656647 -25.355766 -38.542938  30.198391 -1.347459   \n",
       "..           ...         ...        ...        ...        ...       ...   \n",
       "463  -499.660553  226.774216  24.239323 -34.519707  -4.645311 -6.661662   \n",
       "464  -519.125061  196.360794  20.975153 -37.906445  -8.972572 -2.429075   \n",
       "465  -664.719604  237.568832  34.023125 -27.980137   4.174069  5.959048   \n",
       "466  -642.387573  211.626724  58.024738 -17.231331  -9.627137  5.180705   \n",
       "467  -739.442017  198.660782  43.886757 -12.170009  -4.475622  0.800751   \n",
       "\n",
       "            f7         f8        f9        f10  ...          s21         s22  \\\n",
       "0     0.000000   0.000000  0.000000   0.000000  ...   624.980011  624.515686   \n",
       "1     0.000000   0.000000  0.000000   0.000000  ...   741.540604  740.039139   \n",
       "2    -3.974618  -1.122937 -2.315084  -0.782426  ...   986.818085  990.895920   \n",
       "3   -17.122757  -0.672371 -0.464282  -2.445030  ...  1016.501160  762.037048   \n",
       "4   -17.192017   3.857743  2.328808   1.493181  ...   982.200012  978.328552   \n",
       "..         ...        ...       ...        ...  ...          ...         ...   \n",
       "463 -24.467012 -17.183765 -8.609711 -11.367735  ...   676.137314  553.682327   \n",
       "464 -21.040472 -20.170307 -9.023230  -9.146351  ...   688.920212  689.198761   \n",
       "465 -15.679664 -12.246822 -1.270034  -7.274833  ...   687.667694  687.689285   \n",
       "466  -0.984878  -5.853268 -4.523614  -8.410495  ...   689.105835  686.911392   \n",
       "467  -2.979800  -0.826931 -0.203965  -7.412817  ...   682.296982  681.843262   \n",
       "\n",
       "            s23          s24         s25         s26         s27         s28  \\\n",
       "0    625.626717   626.742325  627.196388  628.167343  629.288254    0.000000   \n",
       "1    738.791885   741.518402  965.318375  969.375534  968.527985  971.133652   \n",
       "2    992.306366   992.766876  748.146439  751.155319    0.000000    0.000000   \n",
       "3    757.047043  1000.429916  997.305298  747.657471    0.000000  991.153412   \n",
       "4    974.822617   968.667984  966.926193  941.512299  964.371872    0.000000   \n",
       "..          ...          ...         ...         ...         ...         ...   \n",
       "463  552.782555   552.999458  676.048203  675.833435  675.321121  675.325851   \n",
       "464  690.185700   689.881744  688.283386  688.633118  689.013825  689.306183   \n",
       "465  687.410126   688.717880  689.070664  689.700165  690.522080  690.021896   \n",
       "466  686.934891   686.820145  686.609802  688.552475  689.970245  688.107758   \n",
       "467  682.140198   683.012314  683.336716  683.770065  683.572769  683.122482   \n",
       "\n",
       "            s29          s30  \n",
       "0      0.000000     0.000000  \n",
       "1    974.208984   977.286148  \n",
       "2    747.904053   748.794479  \n",
       "3    993.239441  1000.373993  \n",
       "4      0.000000     0.000000  \n",
       "..          ...          ...  \n",
       "463  675.530701   675.846405  \n",
       "464  689.485626   689.206009  \n",
       "465  691.720810   691.699905  \n",
       "466  687.123413   687.262878  \n",
       "467  683.573990   683.046722  \n",
       "\n",
       "[468 rows x 50 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = pd.concat([extracted_features_df, extracted_skeleton_df],axis=1)\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.to_csv(\"music3_combine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train, Test 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "total_data = pd.read_csv('music2_combine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = []\n",
    "s_list = []\n",
    "for col in total_data.columns:\n",
    "    if (col.find(\"f\")!=-1):\n",
    "        f_list.append(col)\n",
    "    else:\n",
    "        s_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-659.597412</td>\n",
       "      <td>40.892715</td>\n",
       "      <td>-6.337469</td>\n",
       "      <td>2.135688</td>\n",
       "      <td>3.548059</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>2.512327</td>\n",
       "      <td>-0.336857</td>\n",
       "      <td>-0.549686</td>\n",
       "      <td>0.215782</td>\n",
       "      <td>1.039396</td>\n",
       "      <td>1.698405</td>\n",
       "      <td>0.474671</td>\n",
       "      <td>-1.070947</td>\n",
       "      <td>-1.314891</td>\n",
       "      <td>-0.188363</td>\n",
       "      <td>-0.083124</td>\n",
       "      <td>0.201764</td>\n",
       "      <td>0.626399</td>\n",
       "      <td>-0.417951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-292.834778</td>\n",
       "      <td>267.615631</td>\n",
       "      <td>-31.524200</td>\n",
       "      <td>-17.887941</td>\n",
       "      <td>27.018032</td>\n",
       "      <td>-12.516393</td>\n",
       "      <td>-10.344816</td>\n",
       "      <td>-1.591869</td>\n",
       "      <td>-14.941175</td>\n",
       "      <td>-10.007528</td>\n",
       "      <td>-5.137794</td>\n",
       "      <td>-6.208638</td>\n",
       "      <td>-1.840299</td>\n",
       "      <td>-5.119336</td>\n",
       "      <td>-8.581604</td>\n",
       "      <td>-5.596979</td>\n",
       "      <td>-7.949373</td>\n",
       "      <td>-7.917210</td>\n",
       "      <td>-1.329109</td>\n",
       "      <td>-0.840493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-305.223053</td>\n",
       "      <td>244.672012</td>\n",
       "      <td>-3.893402</td>\n",
       "      <td>-44.606812</td>\n",
       "      <td>3.250715</td>\n",
       "      <td>5.895392</td>\n",
       "      <td>1.689971</td>\n",
       "      <td>6.827463</td>\n",
       "      <td>0.744675</td>\n",
       "      <td>-5.771279</td>\n",
       "      <td>-6.333980</td>\n",
       "      <td>-2.251126</td>\n",
       "      <td>5.010935</td>\n",
       "      <td>2.434026</td>\n",
       "      <td>-7.714496</td>\n",
       "      <td>-6.270520</td>\n",
       "      <td>1.998515</td>\n",
       "      <td>0.632427</td>\n",
       "      <td>-5.379352</td>\n",
       "      <td>-6.326122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-315.512512</td>\n",
       "      <td>256.956909</td>\n",
       "      <td>-1.200694</td>\n",
       "      <td>-25.436708</td>\n",
       "      <td>17.819677</td>\n",
       "      <td>-2.204413</td>\n",
       "      <td>-6.866660</td>\n",
       "      <td>6.551411</td>\n",
       "      <td>-3.638557</td>\n",
       "      <td>-9.829278</td>\n",
       "      <td>-2.312829</td>\n",
       "      <td>-0.853408</td>\n",
       "      <td>-0.859357</td>\n",
       "      <td>3.551487</td>\n",
       "      <td>2.857303</td>\n",
       "      <td>-3.297808</td>\n",
       "      <td>-6.639400</td>\n",
       "      <td>-6.634170</td>\n",
       "      <td>-5.738685</td>\n",
       "      <td>-3.462696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-314.082062</td>\n",
       "      <td>263.250031</td>\n",
       "      <td>-4.278464</td>\n",
       "      <td>-26.831131</td>\n",
       "      <td>26.338915</td>\n",
       "      <td>7.504233</td>\n",
       "      <td>-6.451949</td>\n",
       "      <td>3.456089</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>-0.746851</td>\n",
       "      <td>4.305096</td>\n",
       "      <td>1.309869</td>\n",
       "      <td>-1.735513</td>\n",
       "      <td>0.219861</td>\n",
       "      <td>-0.719799</td>\n",
       "      <td>-1.325379</td>\n",
       "      <td>3.927995</td>\n",
       "      <td>7.164885</td>\n",
       "      <td>2.745458</td>\n",
       "      <td>-2.265963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-274.375885</td>\n",
       "      <td>247.054626</td>\n",
       "      <td>-23.015581</td>\n",
       "      <td>-3.219867</td>\n",
       "      <td>10.029488</td>\n",
       "      <td>-18.128145</td>\n",
       "      <td>0.526839</td>\n",
       "      <td>0.349822</td>\n",
       "      <td>-9.175799</td>\n",
       "      <td>-7.860695</td>\n",
       "      <td>-9.392933</td>\n",
       "      <td>-8.148173</td>\n",
       "      <td>-0.438686</td>\n",
       "      <td>7.919487</td>\n",
       "      <td>2.013604</td>\n",
       "      <td>-5.192632</td>\n",
       "      <td>-4.235599</td>\n",
       "      <td>-4.485144</td>\n",
       "      <td>0.216761</td>\n",
       "      <td>0.204451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-267.205414</td>\n",
       "      <td>259.817535</td>\n",
       "      <td>-30.687019</td>\n",
       "      <td>-12.229400</td>\n",
       "      <td>28.597347</td>\n",
       "      <td>-4.391084</td>\n",
       "      <td>3.123246</td>\n",
       "      <td>10.407693</td>\n",
       "      <td>-4.229205</td>\n",
       "      <td>-4.573333</td>\n",
       "      <td>-0.256944</td>\n",
       "      <td>-1.163530</td>\n",
       "      <td>2.427042</td>\n",
       "      <td>5.000734</td>\n",
       "      <td>0.297901</td>\n",
       "      <td>-4.059734</td>\n",
       "      <td>-7.076856</td>\n",
       "      <td>-1.363354</td>\n",
       "      <td>6.904899</td>\n",
       "      <td>-1.689761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-399.051239</td>\n",
       "      <td>292.382385</td>\n",
       "      <td>-0.795051</td>\n",
       "      <td>-45.920994</td>\n",
       "      <td>19.528372</td>\n",
       "      <td>10.774570</td>\n",
       "      <td>-9.688483</td>\n",
       "      <td>8.796929</td>\n",
       "      <td>10.584660</td>\n",
       "      <td>-4.897935</td>\n",
       "      <td>-0.967777</td>\n",
       "      <td>6.988903</td>\n",
       "      <td>1.519527</td>\n",
       "      <td>-0.161918</td>\n",
       "      <td>5.750542</td>\n",
       "      <td>2.316281</td>\n",
       "      <td>-5.852559</td>\n",
       "      <td>-0.523886</td>\n",
       "      <td>7.681949</td>\n",
       "      <td>1.245867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-486.915405</td>\n",
       "      <td>290.128601</td>\n",
       "      <td>45.051098</td>\n",
       "      <td>-47.019325</td>\n",
       "      <td>-5.759301</td>\n",
       "      <td>19.710251</td>\n",
       "      <td>3.713731</td>\n",
       "      <td>1.178202</td>\n",
       "      <td>7.826465</td>\n",
       "      <td>0.669808</td>\n",
       "      <td>-2.894178</td>\n",
       "      <td>6.526373</td>\n",
       "      <td>10.251746</td>\n",
       "      <td>5.296264</td>\n",
       "      <td>3.346136</td>\n",
       "      <td>2.467661</td>\n",
       "      <td>-0.569632</td>\n",
       "      <td>0.249553</td>\n",
       "      <td>2.797758</td>\n",
       "      <td>0.480999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-614.924561</td>\n",
       "      <td>190.049576</td>\n",
       "      <td>66.447845</td>\n",
       "      <td>-0.944410</td>\n",
       "      <td>-8.603423</td>\n",
       "      <td>3.510707</td>\n",
       "      <td>6.209388</td>\n",
       "      <td>2.166924</td>\n",
       "      <td>-0.583799</td>\n",
       "      <td>-1.198471</td>\n",
       "      <td>0.518349</td>\n",
       "      <td>4.447192</td>\n",
       "      <td>6.159729</td>\n",
       "      <td>3.199069</td>\n",
       "      <td>-1.596815</td>\n",
       "      <td>-3.785386</td>\n",
       "      <td>-2.529632</td>\n",
       "      <td>-0.271586</td>\n",
       "      <td>0.824677</td>\n",
       "      <td>-1.257563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f1          f2         f3         f4         f5         f6  \\\n",
       "0   -659.597412   40.892715  -6.337469   2.135688   3.548059   0.804762   \n",
       "1   -292.834778  267.615631 -31.524200 -17.887941  27.018032 -12.516393   \n",
       "2   -305.223053  244.672012  -3.893402 -44.606812   3.250715   5.895392   \n",
       "3   -315.512512  256.956909  -1.200694 -25.436708  17.819677  -2.204413   \n",
       "4   -314.082062  263.250031  -4.278464 -26.831131  26.338915   7.504233   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "123 -274.375885  247.054626 -23.015581  -3.219867  10.029488 -18.128145   \n",
       "124 -267.205414  259.817535 -30.687019 -12.229400  28.597347  -4.391084   \n",
       "125 -399.051239  292.382385  -0.795051 -45.920994  19.528372  10.774570   \n",
       "126 -486.915405  290.128601  45.051098 -47.019325  -5.759301  19.710251   \n",
       "127 -614.924561  190.049576  66.447845  -0.944410  -8.603423   3.510707   \n",
       "\n",
       "            f7         f8         f9        f10       f11       f12  \\\n",
       "0     2.512327  -0.336857  -0.549686   0.215782  1.039396  1.698405   \n",
       "1   -10.344816  -1.591869 -14.941175 -10.007528 -5.137794 -6.208638   \n",
       "2     1.689971   6.827463   0.744675  -5.771279 -6.333980 -2.251126   \n",
       "3    -6.866660   6.551411  -3.638557  -9.829278 -2.312829 -0.853408   \n",
       "4    -6.451949   3.456089   0.358805  -0.746851  4.305096  1.309869   \n",
       "..         ...        ...        ...        ...       ...       ...   \n",
       "123   0.526839   0.349822  -9.175799  -7.860695 -9.392933 -8.148173   \n",
       "124   3.123246  10.407693  -4.229205  -4.573333 -0.256944 -1.163530   \n",
       "125  -9.688483   8.796929  10.584660  -4.897935 -0.967777  6.988903   \n",
       "126   3.713731   1.178202   7.826465   0.669808 -2.894178  6.526373   \n",
       "127   6.209388   2.166924  -0.583799  -1.198471  0.518349  4.447192   \n",
       "\n",
       "           f13       f14       f15       f16       f17       f18       f19  \\\n",
       "0     0.474671 -1.070947 -1.314891 -0.188363 -0.083124  0.201764  0.626399   \n",
       "1    -1.840299 -5.119336 -8.581604 -5.596979 -7.949373 -7.917210 -1.329109   \n",
       "2     5.010935  2.434026 -7.714496 -6.270520  1.998515  0.632427 -5.379352   \n",
       "3    -0.859357  3.551487  2.857303 -3.297808 -6.639400 -6.634170 -5.738685   \n",
       "4    -1.735513  0.219861 -0.719799 -1.325379  3.927995  7.164885  2.745458   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "123  -0.438686  7.919487  2.013604 -5.192632 -4.235599 -4.485144  0.216761   \n",
       "124   2.427042  5.000734  0.297901 -4.059734 -7.076856 -1.363354  6.904899   \n",
       "125   1.519527 -0.161918  5.750542  2.316281 -5.852559 -0.523886  7.681949   \n",
       "126  10.251746  5.296264  3.346136  2.467661 -0.569632  0.249553  2.797758   \n",
       "127   6.159729  3.199069 -1.596815 -3.785386 -2.529632 -0.271586  0.824677   \n",
       "\n",
       "          f20  \n",
       "0   -0.417951  \n",
       "1   -0.840493  \n",
       "2   -6.326122  \n",
       "3   -3.462696  \n",
       "4   -2.265963  \n",
       "..        ...  \n",
       "123  0.204451  \n",
       "124 -1.689761  \n",
       "125  1.245867  \n",
       "126  0.480999  \n",
       "127 -1.257563  \n",
       "\n",
       "[128 rows x 20 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data[f_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_normalize(total_data):\n",
    "    # create training and test set \n",
    "    \n",
    "    inputs = total_data[f_list]\n",
    "    outputs = total_data[s_list]\n",
    "    \n",
    "    ### Train Test Split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test=train_test_split(inputs,outputs,test_size=0.2,random_state=7)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train) # 2차원 변경\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    \n",
    "    X_test, y_test = np.array(X_test), np.array(y_test) # 2차원 변경\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1 )) # LSTM 모델을 위해 3차원 변경\n",
    "    \n",
    "    return X_train, y_train , X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 20)\n",
      "(102, 30)\n",
      "(26, 20)\n",
      "(26, 30)\n",
      "X_train :  (102, 20, 1)  y_train :  (102, 30)\n",
      "X_test :  (26, 20, 1)  y_test :  (26, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_normalize(total_data)\n",
    "print(\"X_train : \",X_train.shape, \" y_train : \", y_train.shape)\n",
    "print(\"X_test : \", X_test.shape, \" y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test):\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "    from keras import optimizers\n",
    "    \n",
    "    # The LSTM architecture\n",
    "    my_LSTM_model = Sequential()\n",
    "    my_LSTM_model.add(LSTM(units = 50, \n",
    "                           return_sequences = True, \n",
    "                           input_shape = (X_train.shape[1],1), \n",
    "                           activation = 'relu'))\n",
    "    my_LSTM_model.add(LSTM(units = 50, activation = 'relu')) # units = 50\n",
    "    my_LSTM_model.add(Dense(units=30))\n",
    "    \n",
    "    # Compiling \n",
    "    my_LSTM_model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "    my_LSTM_model.summary()\n",
    "    \n",
    "    #my_LSTM_model.fit(X_train, y_train, epochs = 50, batch_size = 150, verbose = 0)\n",
    "    #LSTM_prediction = my_LSTM_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    return my_LSTM_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_Run(X_train, y_train, X_test, LSTM_model):\n",
    "    \n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    # model training\n",
    "    batch_size = 512\n",
    "    epoch = 10000\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='loss', patience=30, verbose=1)\n",
    "    \n",
    "    # Fitting to the training set \n",
    "    LSTM_model.fit(X_train, y_train, epochs=epoch, batch_size=batch_size, verbose=1, callbacks=[early_stop])\n",
    "    \n",
    "    LSTM_prediction = my_LSTM_model.predict(X_test)\n",
    "    return LSTM_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(preds):\n",
    "    \n",
    "    actual_pred = pd.DataFrame(columns = ['actual_value', 'prediction'])\n",
    "    actual_pred['actual_value'] = y_test[:, 0]\n",
    "    actual_pred['prediction'] = preds[:,0]\n",
    "\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    m = tf.keras.metrics.MeanSquaredError()\n",
    "    m.update_state(np.array(actual_pred['actual_value']), np.array(actual_pred['prediction']))\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_53 (LSTM)               (None, 20, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 30)                1530      \n",
      "=================================================================\n",
      "Total params: 32,130\n",
      "Trainable params: 32,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_LSTM_model = LSTM_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 830.1478\n",
      "Epoch 2/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 829.7326\n",
      "Epoch 3/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 824.4461\n",
      "Epoch 4/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 809.8705\n",
      "Epoch 5/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 791.9039\n",
      "Epoch 6/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 770.8994\n",
      "Epoch 7/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 746.1529\n",
      "Epoch 8/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 719.4041\n",
      "Epoch 9/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 693.9978\n",
      "Epoch 10/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 673.8063\n",
      "Epoch 11/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 677.2717\n",
      "Epoch 12/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 683.0163\n",
      "Epoch 13/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 668.9200\n",
      "Epoch 14/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 652.4985\n",
      "Epoch 15/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 646.1390\n",
      "Epoch 16/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 646.0108\n",
      "Epoch 17/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 642.5138\n",
      "Epoch 18/10000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 635.4454\n",
      "Epoch 19/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 625.5610\n",
      "Epoch 20/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 615.6976\n",
      "Epoch 21/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 611.2330\n",
      "Epoch 22/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 609.0870\n",
      "Epoch 23/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 603.1210\n",
      "Epoch 24/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 594.2033\n",
      "Epoch 25/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 586.5325\n",
      "Epoch 26/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 581.5859\n",
      "Epoch 27/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 576.7564\n",
      "Epoch 28/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 570.7054\n",
      "Epoch 29/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 563.0489\n",
      "Epoch 30/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 555.3143\n",
      "Epoch 31/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 549.3409\n",
      "Epoch 32/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 544.2465\n",
      "Epoch 33/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 537.0821\n",
      "Epoch 34/10000\n",
      "102/102 [==============================] - 0s 191us/step - loss: 523.8622\n",
      "Epoch 35/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 508.0598\n",
      "Epoch 36/10000\n",
      "102/102 [==============================] - 0s 201us/step - loss: 498.7770\n",
      "Epoch 37/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 490.2019\n",
      "Epoch 38/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 480.9901\n",
      "Epoch 39/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 470.8220\n",
      "Epoch 40/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 460.1479\n",
      "Epoch 41/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 450.4190\n",
      "Epoch 42/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 440.9791\n",
      "Epoch 43/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 430.2632\n",
      "Epoch 44/10000\n",
      "102/102 [==============================] - 0s 245us/step - loss: 420.3016\n",
      "Epoch 45/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 412.1874\n",
      "Epoch 46/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 402.2845\n",
      "Epoch 47/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 391.4951\n",
      "Epoch 48/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 378.3588\n",
      "Epoch 49/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 355.4391\n",
      "Epoch 50/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 341.1816\n",
      "Epoch 51/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 351.1166\n",
      "Epoch 52/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 317.3897\n",
      "Epoch 53/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 307.9279\n",
      "Epoch 54/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 300.2001\n",
      "Epoch 55/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 291.6601\n",
      "Epoch 56/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 283.1803\n",
      "Epoch 57/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 276.3391\n",
      "Epoch 58/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 272.4662\n",
      "Epoch 59/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 267.2862\n",
      "Epoch 60/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 262.1092\n",
      "Epoch 61/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 256.8234\n",
      "Epoch 62/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 250.9685\n",
      "Epoch 63/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 246.0629\n",
      "Epoch 64/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 240.7160\n",
      "Epoch 65/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 235.4278\n",
      "Epoch 66/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 229.9783\n",
      "Epoch 67/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 224.3248\n",
      "Epoch 68/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 220.0357\n",
      "Epoch 69/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 216.0636\n",
      "Epoch 70/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 212.8888\n",
      "Epoch 71/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 209.2701\n",
      "Epoch 72/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 206.1312\n",
      "Epoch 73/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 202.9996\n",
      "Epoch 74/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 200.3554\n",
      "Epoch 75/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 197.5143\n",
      "Epoch 76/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 195.3039\n",
      "Epoch 77/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 193.2765\n",
      "Epoch 78/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 191.7073\n",
      "Epoch 79/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 190.4430\n",
      "Epoch 80/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 189.2149\n",
      "Epoch 81/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 188.1366\n",
      "Epoch 82/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 187.2105\n",
      "Epoch 83/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 186.8046\n",
      "Epoch 84/10000\n",
      "102/102 [==============================] - 0s 274us/step - loss: 188.3329\n",
      "Epoch 85/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 192.5475\n",
      "Epoch 86/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 186.6436\n",
      "Epoch 87/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 197.5555\n",
      "Epoch 88/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 185.8562\n",
      "Epoch 89/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 191.5987\n",
      "Epoch 90/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 183.7466\n",
      "Epoch 91/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 190.3879\n",
      "Epoch 92/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 182.1446\n",
      "Epoch 93/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 186.0126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 184.0459\n",
      "Epoch 95/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 180.9831\n",
      "Epoch 96/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 183.3155\n",
      "Epoch 97/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 180.0285\n",
      "Epoch 98/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 182.1911\n",
      "Epoch 99/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 177.4057\n",
      "Epoch 100/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 182.6013\n",
      "Epoch 101/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 177.0766\n",
      "Epoch 102/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 180.1021\n",
      "Epoch 103/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 176.3065\n",
      "Epoch 104/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 179.6023\n",
      "Epoch 105/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 175.5436\n",
      "Epoch 106/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 178.0669\n",
      "Epoch 107/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 175.4321\n",
      "Epoch 108/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 178.0854\n",
      "Epoch 109/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.7614\n",
      "Epoch 110/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 176.2152\n",
      "Epoch 111/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 174.8455\n",
      "Epoch 112/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 174.9473\n",
      "Epoch 113/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 175.3523\n",
      "Epoch 114/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.1303\n",
      "Epoch 115/10000\n",
      "102/102 [==============================] - 0s 245us/step - loss: 175.5928\n",
      "Epoch 116/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 173.3059\n",
      "Epoch 117/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 173.6090\n",
      "Epoch 118/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.7305\n",
      "Epoch 119/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 174.9635\n",
      "Epoch 120/10000\n",
      "102/102 [==============================] - 0s 255us/step - loss: 174.6094\n",
      "Epoch 121/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 173.7836\n",
      "Epoch 122/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.7214\n",
      "Epoch 123/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.4605\n",
      "Epoch 124/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.4199\n",
      "Epoch 125/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 173.0292\n",
      "Epoch 126/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.2163\n",
      "Epoch 127/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 171.8144\n",
      "Epoch 128/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 171.4039\n",
      "Epoch 129/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 171.4258\n",
      "Epoch 130/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.8060\n",
      "Epoch 131/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 171.9340\n",
      "Epoch 132/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 170.2646\n",
      "Epoch 133/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 169.8934\n",
      "Epoch 134/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 170.3927\n",
      "Epoch 135/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 170.2398\n",
      "Epoch 136/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 171.8921\n",
      "Epoch 137/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 176.4114\n",
      "Epoch 138/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 169.9536\n",
      "Epoch 139/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 187.6045\n",
      "Epoch 140/10000\n",
      "102/102 [==============================] - 0s 245us/step - loss: 188.0954\n",
      "Epoch 141/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 199.4454\n",
      "Epoch 142/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 188.4680\n",
      "Epoch 143/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 175.2054\n",
      "Epoch 144/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 196.2674\n",
      "Epoch 145/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.8519\n",
      "Epoch 146/10000\n",
      "102/102 [==============================] - 0s 215us/step - loss: 184.2504\n",
      "Epoch 147/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 180.8463\n",
      "Epoch 148/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 175.5161\n",
      "Epoch 149/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 181.9240\n",
      "Epoch 150/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.5332\n",
      "Epoch 151/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 178.9187\n",
      "Epoch 152/10000\n",
      "102/102 [==============================] - 0s 235us/step - loss: 174.9556\n",
      "Epoch 153/10000\n",
      "102/102 [==============================] - 0s 245us/step - loss: 175.9229\n",
      "Epoch 154/10000\n",
      "102/102 [==============================] - 0s 226us/step - loss: 175.8676\n",
      "Epoch 155/10000\n",
      "102/102 [==============================] - 0s 196us/step - loss: 173.6719\n",
      "Epoch 156/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 176.1432\n",
      "Epoch 157/10000\n",
      "102/102 [==============================] - 0s 225us/step - loss: 172.7291\n",
      "Epoch 158/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 175.2348\n",
      "Epoch 159/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 172.4003\n",
      "Epoch 160/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 173.3513\n",
      "Epoch 161/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 172.6952\n",
      "Epoch 162/10000\n",
      "102/102 [==============================] - 0s 206us/step - loss: 172.2297\n",
      "Epoch 163/10000\n",
      "102/102 [==============================] - 0s 216us/step - loss: 171.9172\n",
      "Epoch 00163: early stopping\n"
     ]
    }
   ],
   "source": [
    "LSTM_prediction = LSTM_model_Run(X_train, y_train, X_test,my_LSTM_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 정확도 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. 그래프 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84402.97, <matplotlib.axes._subplots.AxesSubplot at 0x268bed44dc8>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LSTM_prediction.shape\n",
    "actual_pred_plot(LSTM_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. 정확도 수치 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370.77601265525607\n",
      "-0.7521017768187345\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, LSTM_prediction))\n",
    "r2 = r2_score(y_test, LSTM_prediction)\n",
    "\n",
    "print(rmse)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 3ms/step\n",
      "224.3509063720703\n"
     ]
    }
   ],
   "source": [
    "score = my_LSTM_model.evaluate(X_test, y_test)\n",
    "print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
