{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\user\\anaconda3\\lib\\site-packages (0.8.10.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (0.9.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (20.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (3.11.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (1.19.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\anaconda3\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from protobuf<4,>=3.11->mediapipe) (49.6.0.post20200814)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Hands in module mediapipe.python.solutions.hands:\n",
      "\n",
      "class Hands(mediapipe.python.solution_base.SolutionBase)\n",
      " |  Hands(static_image_mode=False, max_num_hands=2, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
      " |  \n",
      " |  MediaPipe Hands.\n",
      " |  \n",
      " |  MediaPipe Hands processes an RGB image and returns the hand landmarks and\n",
      " |  handedness (left v.s. right hand) of each detected hand.\n",
      " |  \n",
      " |  Note that it determines handedness assuming the input image is mirrored,\n",
      " |  i.e., taken with a front-facing/selfie camera (\n",
      " |  https://en.wikipedia.org/wiki/Front-facing_camera) with images flipped\n",
      " |  horizontally. If that is not the case, use, for instance, cv2.flip(image, 1)\n",
      " |  to flip the image first for a correct handedness output.\n",
      " |  \n",
      " |  Please refer to https://solutions.mediapipe.dev/hands#python-solution-api for\n",
      " |  usage examples.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Hands\n",
      " |      mediapipe.python.solution_base.SolutionBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, static_image_mode=False, max_num_hands=2, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
      " |      Initializes a MediaPipe Hand object.\n",
      " |      \n",
      " |      Args:\n",
      " |        static_image_mode: Whether to treat the input images as a batch of static\n",
      " |          and possibly unrelated images, or a video stream. See details in\n",
      " |          https://solutions.mediapipe.dev/hands#static_image_mode.\n",
      " |        max_num_hands: Maximum number of hands to detect. See details in\n",
      " |          https://solutions.mediapipe.dev/hands#max_num_hands.\n",
      " |        model_complexity: Complexity of the hand landmark model: 0 or 1.\n",
      " |          Landmark accuracy as well as inference latency generally go up with the\n",
      " |          model complexity. See details in\n",
      " |          https://solutions.mediapipe.dev/hands#model_complexity.\n",
      " |        min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for hand\n",
      " |          detection to be considered successful. See details in\n",
      " |          https://solutions.mediapipe.dev/hands#min_detection_confidence.\n",
      " |        min_tracking_confidence: Minimum confidence value ([0.0, 1.0]) for the\n",
      " |          hand landmarks to be considered tracked successfully. See details in\n",
      " |          https://solutions.mediapipe.dev/hands#min_tracking_confidence.\n",
      " |  \n",
      " |  process(self, image: numpy.ndarray) -> <class 'NamedTuple'>\n",
      " |      Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: An RGB image represented as a numpy ndarray.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the underlying graph throws any error.\n",
      " |        ValueError: If the input image is not three channel RGB.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A NamedTuple object with the following fields:\n",
      " |          1) a \"multi_hand_landmarks\" field that contains the hand landmarks on\n",
      " |             each detected hand.\n",
      " |          2) a \"multi_hand_world_landmarks\" field that contains the hand landmarks\n",
      " |             on each detected hand in real-world 3D coordinates that are in meters\n",
      " |             with the origin at the hand's approximate geometric center.\n",
      " |          3) a \"multi_handedness\" field that contains the handedness (left v.s.\n",
      " |             right hand) of the detected hand.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mediapipe.python.solution_base.SolutionBase:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      A \"with\" statement support.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      " |      Closes all the input sources and the graph.\n",
      " |  \n",
      " |  close(self) -> None\n",
      " |      Closes all the input sources and the graph.\n",
      " |  \n",
      " |  create_graph_options(self, options_message: google.protobuf.message.Message, values: Mapping[str, Any]) -> google.protobuf.message.Message\n",
      " |      Sets protobuf field values.\n",
      " |      \n",
      " |      Args:\n",
      " |        options_message: the options protobuf message.\n",
      " |        values: field value pairs, where each field may be a \".\" separated path.\n",
      " |      \n",
      " |      Returns:\n",
      " |        the options protobuf message.\n",
      " |  \n",
      " |  reset(self) -> None\n",
      " |      Resets the graph for another run.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mediapipe.python.solution_base.SolutionBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "help(mp_hands.Hands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
